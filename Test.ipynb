{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5db25b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14659/3884596303.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.pandas.set_option('display.max_columns',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b50362e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('yellow_tripdata_2023-01.csv',low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14c5ea9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "after_filtered_df=df[df['VendorID'] != 'VendorID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "336bc6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "after_filtered_df['VendorID']=after_filtered_df['VendorID'].astype('category')\n",
    "after_filtered_df['tpep_pickup_datetime']=pd.to_datetime(after_filtered_df['tpep_pickup_datetime'])\n",
    "after_filtered_df['tpep_dropoff_datetime']=pd.to_datetime(after_filtered_df['tpep_dropoff_datetime'])\n",
    "after_filtered_df['passenger_count']=pd.to_numeric(after_filtered_df['passenger_count'],downcast='integer')\n",
    "after_filtered_df['trip_distance']=pd.to_numeric(after_filtered_df['trip_distance'])\n",
    "after_filtered_df['RatecodeID']=after_filtered_df['RatecodeID'].astype('category')\n",
    "after_filtered_df['store_and_fwd_flag']=after_filtered_df['store_and_fwd_flag'].astype('category')\n",
    "after_filtered_df['PULocationID']=pd.to_numeric(after_filtered_df['PULocationID'])\n",
    "after_filtered_df['DOLocationID']=pd.to_numeric(after_filtered_df['DOLocationID'])\n",
    "after_filtered_df['payment_type']=after_filtered_df['payment_type'].astype('category')\n",
    "after_filtered_df['fare_amount']=pd.to_numeric(after_filtered_df['fare_amount'])\n",
    "after_filtered_df['extra']=pd.to_numeric(after_filtered_df['extra'])\n",
    "after_filtered_df['mta_tax']=pd.to_numeric(after_filtered_df['mta_tax'])\n",
    "after_filtered_df['tip_amount']=pd.to_numeric(after_filtered_df['tip_amount'])\n",
    "after_filtered_df['tolls_amount']=pd.to_numeric(after_filtered_df['tolls_amount'])\n",
    "after_filtered_df['improvement_surcharge']=pd.to_numeric(after_filtered_df['improvement_surcharge'])\n",
    "after_filtered_df['total_amount']=pd.to_numeric(after_filtered_df['total_amount'])\n",
    "after_filtered_df['congestion_surcharge']=pd.to_numeric(after_filtered_df['congestion_surcharge'])\n",
    "after_filtered_df['airport_fee']=pd.to_numeric(after_filtered_df['airport_fee'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63e566cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3066766 entries, 0 to 3066811\n",
      "Data columns (total 19 columns):\n",
      " #   Column                 Dtype         \n",
      "---  ------                 -----         \n",
      " 0   VendorID               category      \n",
      " 1   tpep_pickup_datetime   datetime64[ns]\n",
      " 2   tpep_dropoff_datetime  datetime64[ns]\n",
      " 3   passenger_count        float64       \n",
      " 4   trip_distance          float64       \n",
      " 5   RatecodeID             category      \n",
      " 6   store_and_fwd_flag     category      \n",
      " 7   PULocationID           int64         \n",
      " 8   DOLocationID           int64         \n",
      " 9   payment_type           category      \n",
      " 10  fare_amount            float64       \n",
      " 11  extra                  float64       \n",
      " 12  mta_tax                float64       \n",
      " 13  tip_amount             float64       \n",
      " 14  tolls_amount           float64       \n",
      " 15  improvement_surcharge  float64       \n",
      " 16  total_amount           float64       \n",
      " 17  congestion_surcharge   float64       \n",
      " 18  airport_fee            float64       \n",
      "dtypes: category(4), datetime64[ns](2), float64(11), int64(2)\n",
      "memory usage: 386.1 MB\n"
     ]
    }
   ],
   "source": [
    "after_filtered_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2546ecd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'yellow_tripdata_2023_01_test' created successfully\n",
      "Error while connecting to PostgreSQL or inserting data: invalid input syntax for type integer: \"1.0\"\n",
      "LINE 5: ... ('2','2023-01-01 00:32:10','2023-01-01 00:40:36','1.0','0.9...\n",
      "                                                             ^\n",
      "\n",
      "PostgreSQL connection is closed\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "from psycopg2 import extras\n",
    "\n",
    "try:\n",
    "    # Establishing the connection\n",
    "    conn = psycopg2.connect(\n",
    "        database=\"postgres\", user='postgres', password='password', host='127.0.0.1', port='5432')\n",
    "    \n",
    "    # Creating a cursor object using the cursor() method\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Create table yellow_tripdata_2023_01 if not exists\n",
    "    cursor.execute('''CREATE TABLE IF NOT EXISTS yellow_tripdata_2023_01_test (\n",
    "                            id SERIAL PRIMARY KEY,\n",
    "                            VendorID int, \n",
    "                            tpep_pickup_datetime TEXT,\n",
    "                            tpep_dropoff_datetime TEXT,\n",
    "                            passenger_count int,\n",
    "                            trip_distance float,\n",
    "                            RatecodeID int,\n",
    "                            store_and_fwd_flag int,\n",
    "                            PULocationID int,\n",
    "                            DOLocationID int,\n",
    "                            payment_type int,\n",
    "                            fare_amount float,\n",
    "                            extra float,\n",
    "                            mta_tax float,\n",
    "                            tip_amount float,\n",
    "                            tolls_amount float,\n",
    "                            improvement_surcharge float,\n",
    "                            total_amount float,\n",
    "                            congestion_surcharge float,\n",
    "                            airport_fee float);''')\n",
    "    \n",
    "    # Commit the table creation\n",
    "    conn.commit()\n",
    "    print(\"Table 'yellow_tripdata_2023_01_test' created successfully\")\n",
    "    \n",
    "    # Prepare data as a list of tuples\n",
    "    data = [tuple(row) for row in df.itertuples(index=False, name=None)]\n",
    "    \n",
    "    # Construct the INSERT INTO statement\n",
    "    insert_query = \"\"\"\n",
    "        INSERT INTO yellow_tripdata_2023_01_test (VendorID, tpep_pickup_datetime, tpep_dropoff_datetime, passenger_count, \n",
    "        trip_distance, RatecodeID, store_and_fwd_flag, PULocationID, DOLocationID, payment_type, fare_amount, extra, \n",
    "        mta_tax, tip_amount, tolls_amount, improvement_surcharge, total_amount, congestion_surcharge, airport_fee)\n",
    "        VALUES %s\n",
    "    \"\"\"\n",
    "    \n",
    "    # Execute the INSERT INTO statement using execute_values()\n",
    "    extras.execute_values(cursor, insert_query, data, page_size=100000) #page_size is number of rows to be inserted  \n",
    "    \n",
    "    # Committing the transaction\n",
    "    conn.commit()\n",
    "    print(\"Data inserted successfully in yellow_tripdata_2023_01_test table\")\n",
    "    \n",
    "except (Exception, psycopg2.Error) as error:\n",
    "    print(\"Error while connecting to PostgreSQL or inserting data:\", error)\n",
    "\n",
    "finally:\n",
    "    # Closing the connection\n",
    "    if conn:\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "        print(\"PostgreSQL connection is closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "baae1f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def test_func():\n",
    "    rate_dim_data={'rate_id':[1,2,3,4,5,6],\n",
    "                  'rate_description':[\"Standard rate\",\"JFK\",\"Newark\",\"Nassau or Westchester\",\n",
    "                                         \"Negotiated fare\",\"Group ride\"]\n",
    "                    }\n",
    "    rate_dim=pd.DataFrame(rate_dim_data)\n",
    "\n",
    "\n",
    "    #prepare data for store_and_forward_dim table\n",
    "    store_and_forward_dim_data={'store_and_forward_id':[1,2],\n",
    "                  'store_and_forward_flag':[\"Y\",\"N\"],\n",
    "                  'store_and_forward_description':[\"store and forward trip\",\"not a store and forward trip\"]\n",
    "                    }\n",
    "    store_and_forward_dim=pd.DataFrame(store_and_forward_dim_data)\n",
    "\n",
    "    #prepare data for vendor_dim table\n",
    "    after_duplicate_filtered_df_data={\n",
    "                    \"Y\":1,\n",
    "                    \"N\":2}\n",
    "    data_frame_dict={\n",
    "        'payment_dim':payment_dim,\n",
    "        'rate_dim':rate_dim,\n",
    "        'store_and_forward_dim':store_and_forward_dim\n",
    "    }\n",
    "    \n",
    "    return data_frame_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ef9f49c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_frame_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m df,name \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdata_frame_dict\u001b[49m\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(df)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_frame_dict' is not defined"
     ]
    }
   ],
   "source": [
    "for df,name in data_frame_dict.items():\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f99397",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052775c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
